{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Vnb8ypPylG95Do8dTGiQgzbPBwo598lN","authorship_tag":"ABX9TyO5lM+CV3azgCHTdC+1+P41"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import numpy as np\n","import torch\n","import sys\n","import copy\n","import random\n","import numpy as np\n","from collections import defaultdict\n","from multiprocessing import Process, Queue\n","import json\n","import os\n","import time\n","from google.colab import drive"],"metadata":{"id":"ouQokaPNK8bN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q1rImkHWFdXg","executionInfo":{"status":"ok","timestamp":1733334625401,"user_tz":180,"elapsed":120069,"user":{"displayName":"Kevin Cespedes Arancibia","userId":"15919322234379898396"}},"outputId":"c0c2254b-99e5-41b2-fa62-0b3237d60345"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q4WVIROcrljq"},"outputs":[],"source":["class PointWiseFeedForward(torch.nn.Module):\n","    def __init__(self, hidden_units, dropout_rate):\n","\n","        super(PointWiseFeedForward, self).__init__()\n","\n","        self.conv1 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n","        self.dropout1 = torch.nn.Dropout(p=dropout_rate)\n","        self.relu = torch.nn.ReLU()\n","        self.conv2 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n","        self.dropout2 = torch.nn.Dropout(p=dropout_rate)\n","\n","    def forward(self, inputs):\n","        outputs = self.dropout2(self.conv2(self.relu(self.dropout1(self.conv1(inputs.transpose(-1, -2))))))\n","        outputs = outputs.transpose(-1, -2) # as Conv1D requires (N, C, Length)\n","        outputs += inputs\n","        return outputs\n","\n","# pls use the following self-made multihead attention layer\n","# in case your pytorch version is below 1.16 or for other reasons\n","# https://github.com/pmixer/TiSASRec.pytorch/blob/master/model.py\n","\n","class SASRec(torch.nn.Module):\n","    def __init__(self, user_num, item_num, args):\n","        super(SASRec, self).__init__()\n","\n","        self.user_num = user_num\n","        self.item_num = item_num\n","        self.dev = args.device\n","\n","        # TODO: loss += args.l2_emb for regularizing embedding vectors during training\n","        # https://stackoverflow.com/questions/42704283/adding-l1-l2-regularization-in-pytorch\n","        self.item_emb = torch.nn.Embedding(self.item_num+1, args.hidden_units, padding_idx=0)\n","        self.pos_emb = torch.nn.Embedding(args.maxlen+1, args.hidden_units, padding_idx=0)\n","        self.emb_dropout = torch.nn.Dropout(p=args.dropout_rate)\n","\n","        self.attention_layernorms = torch.nn.ModuleList() # to be Q for self-attention\n","        self.attention_layers = torch.nn.ModuleList()\n","        self.forward_layernorms = torch.nn.ModuleList()\n","        self.forward_layers = torch.nn.ModuleList()\n","\n","        self.last_layernorm = torch.nn.LayerNorm(args.hidden_units, eps=1e-8)\n","\n","        for _ in range(args.num_blocks):\n","            new_attn_layernorm = torch.nn.LayerNorm(args.hidden_units, eps=1e-8)\n","            self.attention_layernorms.append(new_attn_layernorm)\n","\n","            new_attn_layer =  torch.nn.MultiheadAttention(args.hidden_units,\n","                                                            args.num_heads,\n","                                                            args.dropout_rate)\n","            self.attention_layers.append(new_attn_layer)\n","\n","            new_fwd_layernorm = torch.nn.LayerNorm(args.hidden_units, eps=1e-8)\n","            self.forward_layernorms.append(new_fwd_layernorm)\n","\n","            new_fwd_layer = PointWiseFeedForward(args.hidden_units, args.dropout_rate)\n","            self.forward_layers.append(new_fwd_layer)\n","\n","            # self.pos_sigmoid = torch.nn.Sigmoid()\n","            # self.neg_sigmoid = torch.nn.Sigmoid()\n","\n","    def log2feats(self, log_seqs): # TODO: fp64 and int64 as default in python, trim?\n","        seqs = self.item_emb(torch.LongTensor(log_seqs).to(self.dev))\n","        seqs *= self.item_emb.embedding_dim ** 0.5\n","        poss = np.tile(np.arange(1, log_seqs.shape[1] + 1), [log_seqs.shape[0], 1])\n","        # TODO: directly do tensor = torch.arange(1, xxx, device='cuda') to save extra overheads\n","        poss *= (log_seqs != 0)\n","        seqs += self.pos_emb(torch.LongTensor(poss).to(self.dev))\n","        seqs = self.emb_dropout(seqs)\n","\n","        tl = seqs.shape[1] # time dim len for enforce causality\n","        attention_mask = ~torch.tril(torch.ones((tl, tl), dtype=torch.bool, device=self.dev))\n","\n","        for i in range(len(self.attention_layers)):\n","            seqs = torch.transpose(seqs, 0, 1)\n","            Q = self.attention_layernorms[i](seqs)\n","            mha_outputs, _ = self.attention_layers[i](Q, seqs, seqs,\n","                                            attn_mask=attention_mask)\n","                                            # need_weights=False) this arg do not work?\n","            seqs = Q + mha_outputs\n","            seqs = torch.transpose(seqs, 0, 1)\n","\n","            seqs = self.forward_layernorms[i](seqs)\n","            seqs = self.forward_layers[i](seqs)\n","\n","        log_feats = self.last_layernorm(seqs) # (U, T, C) -> (U, -1, C)\n","\n","        return log_feats\n","\n","    def forward(self, user_ids, log_seqs, pos_seqs, neg_seqs): # for training\n","        log_feats = self.log2feats(log_seqs) # user_ids hasn't been used yet\n","\n","        pos_embs = self.item_emb(torch.LongTensor(pos_seqs).to(self.dev))\n","        neg_embs = self.item_emb(torch.LongTensor(neg_seqs).to(self.dev))\n","\n","        pos_logits = (log_feats * pos_embs).sum(dim=-1)\n","        neg_logits = (log_feats * neg_embs).sum(dim=-1)\n","\n","        # pos_pred = self.pos_sigmoid(pos_logits)\n","        # neg_pred = self.neg_sigmoid(neg_logits)\n","\n","        return pos_logits, neg_logits # pos_pred, neg_pred\n","\n","    def predict(self, user_ids, log_seqs, item_indices): # for inference\n","        log_feats = self.log2feats(log_seqs) # user_ids hasn't been used yet\n","\n","        final_feat = log_feats[:, -1, :] # only use last QKV classifier, a waste\n","\n","        item_embs = self.item_emb(torch.LongTensor(item_indices).to(self.dev)) # (U, I, C)\n","\n","        logits = item_embs.matmul(final_feat.unsqueeze(-1)).squeeze(-1)\n","\n","        # preds = self.pos_sigmoid(logits) # rank same item list for different users\n","\n","        return logits # preds # (U, I)"]},{"cell_type":"code","source":["def read_json_file(file_path):\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","    return data\n","\n","data_dir = 'drive/My Drive/puc/rec/project/data'\n","data_file = 'playlistid_itemid_1000p_train.txt'\n","\n","def build_index(n_users=999, n_items=34443):\n","\n","    ui_mat = np.loadtxt(f'{data_dir}/{data_file}', dtype=np.int32)\n","\n","    n_users = ui_mat[:, 0].max()\n","    n_items = ui_mat[:, 1].max()\n","\n","    u2i_index = [[] for _ in range(n_users + 1)]\n","    i2u_index = [[] for _ in range(n_items + 1)]\n","\n","    for ui_pair in ui_mat:\n","        u2i_index[ui_pair[0]].append(ui_pair[1])\n","        i2u_index[ui_pair[1]].append(ui_pair[0])\n","\n","    return u2i_index, i2u_index\n","\n","# sampler for batch generation\n","def random_neq(l, r, s):\n","    t = np.random.randint(l, r)\n","    while t in s:\n","        t = np.random.randint(l, r)\n","    return t\n","\n","\n","def sample_function(user_train, usernum, itemnum, batch_size, maxlen, result_queue, SEED):\n","    def sample(uid):\n","\n","        # uid = np.random.randint(1, usernum + 1)\n","        user_train_keys = list(user_train.keys())\n","        while (uid not in user_train) or (len(user_train[uid]) <= 1):\n","          uid = np.random.randint(1, usernum + 1)\n","\n","        seq = np.zeros([maxlen], dtype=np.int32)\n","        pos = np.zeros([maxlen], dtype=np.int32)\n","        neg = np.zeros([maxlen], dtype=np.int32)\n","        nxt = user_train[uid][-1]\n","        idx = maxlen - 1\n","\n","        ts = set(user_train[uid])\n","        for i in reversed(user_train[uid][:-1]):\n","            seq[idx] = i\n","            pos[idx] = nxt\n","            if nxt != 0: neg[idx] = random_neq(1, itemnum + 1, ts)\n","            nxt = i\n","            idx -= 1\n","            if idx == -1: break\n","\n","        return (uid, seq, pos, neg)\n","\n","    np.random.seed(SEED)\n","\n","    # user_train_uids = np.array(list(user_train.keys()))\n","\n","    uids = np.arange(1, usernum+1, dtype=np.int32)\n","    # uids = uids[np.isin(uids, user_train_uids)]\n","    counter = 0\n","    while True:\n","        if counter % usernum == 0:\n","            np.random.shuffle(uids)\n","        one_batch = []\n","        for i in range(batch_size):\n","            one_batch.append(sample(uids[counter % usernum]))\n","            counter += 1\n","        result_queue.put(zip(*one_batch))\n","\n","\n","# train/val/test data generation\n","def data_partition():\n","    usernum = 0\n","    itemnum = 0\n","    User = defaultdict(list)\n","    user_train = {}\n","    user_valid = {}\n","    user_test = {}\n","    # assume user/item index starting from 1\n","    f = open(f'{data_dir}/{data_file}', 'r')\n","    for line in f:\n","        u, i = line.rstrip().split(' ')\n","        u = int(u)\n","        i = int(i)\n","        usernum = max(u, usernum)\n","        itemnum = max(i, itemnum)\n","        User[u].append(i)\n","\n","    for user in User:\n","        nfeedback = len(User[user])\n","        if nfeedback < 3:\n","            user_train[user] = User[user]\n","            user_valid[user] = []\n","            user_test[user] = []\n","        else:\n","            user_train[user] = User[user][:-2]\n","            user_valid[user] = []\n","            user_valid[user].append(User[user][-2])\n","            user_test[user] = []\n","            user_test[user].append(User[user][-1])\n","    return [user_train, user_valid]\n","\n","# TODO: merge evaluate functions for test and val set\n","# evaluate on test set\n","def evaluate(model, dataset, args):\n","    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n","\n","    NDCG = 0.0\n","    HT = 0.0\n","    valid_user = 0.0\n","\n","    if usernum>10000:\n","        users = random.sample(range(1, usernum + 1), 10000)\n","    else:\n","        users = range(1, usernum + 1)\n","    for u in users:\n","\n","        if len(train[u]) < 1 or len(test[u]) < 1: continue\n","\n","        seq = np.zeros([args.maxlen], dtype=np.int32)\n","        idx = args.maxlen - 1\n","        seq[idx] = valid[u][0]\n","        idx -= 1\n","        for i in reversed(train[u]):\n","            seq[idx] = i\n","            idx -= 1\n","            if idx == -1: break\n","        rated = set(train[u])\n","        rated.add(0)\n","        item_idx = [test[u][0]]\n","        for _ in range(100):\n","            t = np.random.randint(1, itemnum + 1)\n","            while t in rated: t = np.random.randint(1, itemnum + 1)\n","            item_idx.append(t)\n","\n","        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], item_idx]])\n","        predictions = predictions[0] # - for 1st argsort DESC\n","\n","        rank = predictions.argsort().argsort()[0].item()\n","\n","        valid_user += 1\n","\n","        if rank < 10:\n","            NDCG += 1 / np.log2(rank + 2)\n","            HT += 1\n","        if valid_user % 100 == 0:\n","            print('.', end=\"\")\n","            sys.stdout.flush()\n","\n","    return NDCG / valid_user, HT / valid_user\n","\n","\n","# evaluate on val set\n","def evaluate_valid(model, dataset, args):\n","    [train, valid, usernum, itemnum] = copy.deepcopy(dataset)\n","\n","    NDCG = 0.0\n","    valid_user = 0.0\n","    HT = 0.0\n","    users= train.keys()\n","    # if usernum>10000:\n","    #     users = random.sample(range(1, usernum + 1), 10000)\n","    # else:\n","    #     users = range(1, usernum + 1)\n","    for u in users:\n","        if len(train[u]) < 1 or len(valid[u]) < 1: continue\n","\n","        seq = np.zeros([args.maxlen], dtype=np.int32)\n","        idx = args.maxlen - 1\n","        for i in reversed(train[u]):\n","            seq[idx] = i\n","            idx -= 1\n","            if idx == -1: break\n","\n","        rated = set(train[u])\n","        rated.add(0)\n","        item_idx = [valid[u][0]]\n","        for _ in range(100):\n","            t = np.random.randint(1, itemnum + 1)\n","            while t in rated: t = np.random.randint(1, itemnum + 1)\n","            item_idx.append(t)\n","\n","        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], item_idx]])\n","        predictions = predictions[0]\n","\n","        rank = predictions.argsort().argsort()[0].item()\n","\n","        valid_user += 1\n","\n","        if rank < 10:\n","            NDCG += 1 / np.log2(rank + 2)\n","            HT += 1\n","        if valid_user % 100 == 0:\n","            print('.', end=\"\")\n","            sys.stdout.flush()\n","\n","    return NDCG / valid_user, HT / valid_user"],"metadata":{"id":"49vVrkivsgRq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def str2bool(s):\n","    if s not in {'false', 'true'}:\n","        raise ValueError('Not a valid boolean string')\n","    return s == 'true'\n","\n","# parser.add_argument('--dataset', required=True)\n","# parser.add_argument('--train_dir', required=True)\n","# parser.add_argument('--batch_size', default=128, type=int)\n","# parser.add_argument('--lr', default=0.001, type=float)\n","# parser.add_argument('--maxlen', default=200, type=int)\n","# parser.add_argument('--hidden_units', default=50, type=int)\n","# parser.add_argument('--num_blocks', default=2, type=int)\n","# parser.add_argument('--num_epochs', default=1000, type=int)\n","# parser.add_argument('--num_heads', default=1, type=int)\n","# parser.add_argument('--dropout_rate', default=0.2, type=float)\n","# parser.add_argument('--l2_emb', default=0.0, type=float)\n","# parser.add_argument('--device', default='cuda', type=str)\n","# parser.add_argument('--inference_only', default=False, type=str2bool)\n","# parser.add_argument('--state_dict_path', default=None, type=str)\n","\n","\n","# if not os.path.isdir(args.dataset + '_' + args.train_dir):\n","#     os.makedirs(args.dataset + '_' + args.train_dir)\n","# with open(os.path.join(args.dataset + '_' + args.train_dir, 'args.txt'), 'w') as f:\n","#     f.write('\\n'.join([str(k) + ',' + str(v) for k, v in sorted(vars(args).items(), key=lambda x: x[0])]))\n","# f.close()\n","\n","class Args:\n","    def __init__(self, **entries):\n","        self.__dict__.update(entries)\n","\n","args = Args(\n","    batch_size=256,\n","    hidden_units=1024,\n","    maxlen=200,\n","    num_blocks=2,\n","    num_heads=1,\n","    device='cuda',\n","    state_dict_path=None,\n","    inference_only=False,\n","    l2_emb=0.0,\n","    dropout_rate=0.2,\n","    num_epochs=100,\n","    lr=0.001,\n","    train_dir='drive/My Drive/puc/rec/project/models',\n","    dataset='playlistid_itemid_1000p_train'\n",")\n","\n","\n","# args.batch_size = 128\n","# args.hidden_units = 50\n","# args.maxlen = 200\n","# args.num_blocks = 2\n","# args.num_heads = 1\n","# args.device = 'cuda'\n","\n","# args.state_dict_path = None\n","# args.inference_only = False\n","\n","# args.l2_emb = 0.0\n","# args.dropout_rate = 0.2\n","# args.num_epochs = 1000\n","\n","\n","u2i_index, i2u_index = build_index()\n","\n","# global dataset\n","dataset = data_partition()\n","\n","usernum = 999\n","itemnum = 34443\n","\n","[user_train, user_valid] = dataset\n","dataset.append(usernum)\n","dataset.append(itemnum)\n","# num_batch = len(user_train) // args.batch_size # tail? + ((len(user_train) % args.batch_size) != 0)\n","num_batch = (len(user_train) - 1) // args.batch_size + 1\n","cc = 0.0\n","for u in user_train:\n","    cc += len(user_train[u])\n","print('average sequence length: %.2f' % (cc / len(user_train)))\n","\n","# f = open(os.path.join(args.dataset + '_' + args.train_dir, 'log.txt'), 'w')\n","# f.write('epoch (val_ndcg, val_hr) (test_ndcg, test_hr)\\n')\n","\n","sampler = WarpSampler(user_train, usernum, itemnum, batch_size=args.batch_size, maxlen=args.maxlen, n_workers=3)"],"metadata":{"id":"VuSVevefsSZt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733336139476,"user_tz":180,"elapsed":556,"user":{"displayName":"Kevin Cespedes Arancibia","userId":"15919322234379898396"}},"outputId":"4771c4a3-eea2-45c8-9d7a-a41f2eb7060f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["average sequence length: 61.61\n"]}]},{"cell_type":"code","source":["model = SASRec(usernum, itemnum, args).to(args.device) # no ReLU activation in original SASRec implementation?\n","\n","for name, param in model.named_parameters():\n","    try:\n","        torch.nn.init.xavier_normal_(param.data)\n","    except:\n","        pass # just ignore those failed init layers\n","\n","model.pos_emb.weight.data[0, :] = 0\n","model.item_emb.weight.data[0, :] = 0\n","\n","# this fails embedding init 'Embedding' object has no attribute 'dim'\n","# model.apply(torch.nn.init.xavier_uniform_)\n","\n","model.train() # enable model training\n","\n","epoch_start_idx = 1\n","if args.state_dict_path is not None:\n","    try:\n","        model.load_state_dict(torch.load(args.state_dict_path, map_location=torch.device(args.device)))\n","        tail = args.state_dict_path[args.state_dict_path.find('epoch=') + 6:]\n","        epoch_start_idx = int(tail[:tail.find('.')]) + 1\n","    except: # in case your pytorch version is not 1.6 etc., pls debug by pdb if load weights failed\n","        print('failed loading state_dicts, pls check file path: ', end=\"\")\n","        print(args.state_dict_path)\n","        print('pdb enabled for your quick check, pls type exit() if you do not need it')\n","        import pdb; pdb.set_trace()\n","\n","\n","if args.inference_only:\n","    model.eval()\n","    t_test = evaluate(model, dataset, args)\n","    print('test (NDCG@10: %.4f, HR@10: %.4f)' % (t_test[0], t_test[1]))\n","\n","# ce_criterion = torch.nn.CrossEntropyLoss()\n","# https://github.com/NVIDIA/pix2pixHD/issues/9 how could an old bug appear again...\n","bce_criterion = torch.nn.BCEWithLogitsLoss() # torch.nn.BCELoss()\n","adam_optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.98))\n","\n","best_val_ndcg, best_val_hr = 0.0, 0.0\n","best_test_ndcg, best_test_hr = 0.0, 0.0\n","T = 0.0\n","t0 = time.time()\n","\n","\n","train_losses = []\n","ndcgs_valid = []\n","ndcgs_test = []\n","hr_valid = []\n","hr_test = []\n","\n","\n","for epoch in range(epoch_start_idx, args.num_epochs + 1):\n","    if args.inference_only: break # just to decrease identition\n","    for step in range(num_batch): # tqdm(range(num_batch), total=num_batch, ncols=70, leave=False, unit='b'):\n","        u, seq, pos, neg = sampler.next_batch() # tuples to ndarray\n","        u, seq, pos, neg = np.array(u), np.array(seq), np.array(pos), np.array(neg)\n","        pos_logits, neg_logits = model(u, seq, pos, neg)\n","        pos_labels, neg_labels = torch.ones(pos_logits.shape, device=args.device), torch.zeros(neg_logits.shape, device=args.device)\n","        # print(\"\\neye ball check raw_logits:\"); print(pos_logits); print(neg_logits) # check pos_logits > 0, neg_logits < 0\n","        adam_optimizer.zero_grad()\n","        indices = np.where(pos != 0)\n","        loss = bce_criterion(pos_logits[indices], pos_labels[indices])\n","        loss += bce_criterion(neg_logits[indices], neg_labels[indices])\n","        for param in model.item_emb.parameters(): loss += args.l2_emb * torch.norm(param)\n","        loss.backward()\n","        adam_optimizer.step()\n","        print(\"loss in epoch {} iteration {}: {}\".format(epoch, step, loss.item())) # expected 0.4~0.6 after init few epochs\n","        train_losses.append(loss.item())\n","\n","    if epoch % 20 == 0:\n","        model.eval()\n","        t1 = time.time() - t0\n","        T += t1\n","        # print('Evaluating', end='')\n","        # t_test = evaluate(model, dataset, args)\n","        t_valid = evaluate_valid(model, dataset, args)\n","        print('epoch:%d, time: %f(s), valid (NDCG@10: %.4f, HR@10: %.4f)'\n","                % (epoch, T, t_valid[0], t_valid[1]))\n","        ndcgs_valid.append(t_valid[0])\n","        hr_valid.append(t_valid[1])\n","\n","\n","        if t_valid[0] > best_val_ndcg or t_valid[1] > best_val_hr:\n","            best_val_ndcg = max(t_valid[0], best_val_ndcg)\n","            best_val_hr = max(t_valid[1], best_val_hr)\n","            # folder = args.dataset + '_' + args.train_dir\n","            # fname = 'SASRec.epoch={}.lr={}.layer={}.head={}.hidden={}.maxlen={}.pth'\n","            # fname = fname.format(epoch, args.lr, args.num_blocks, args.num_heads, args.hidden_units, args.maxlen)\n","            # torch.save(model.state_dict(), os.path.join(folder, fname))\n","\n","        # f.write(str(epoch) + ' ' + str(t_valid) + ' ' + str(t_test) + '\\n')\n","        # f.flush()\n","        t0 = time.time()\n","        model.train()\n","\n","    # if epoch == args.num_epochs:\n","    #     folder = args.dataset + '_' + args.train_dir\n","    #     fname = 'SASRec.epoch={}.lr={}.layer={}.head={}.hidden={}.maxlen={}.pth'\n","    #     fname = fname.format(args.num_epochs, args.lr, args.num_blocks, args.num_heads, args.hidden_units, args.maxlen)\n","    #     torch.save(model.state_dict(), os.path.join(folder, fname))\n","\n","# f.close()\n","sampler.close()\n","print(\"Done\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfzqxh4ushIe","executionInfo":{"status":"ok","timestamp":1733336724888,"user_tz":180,"elapsed":578753,"user":{"displayName":"Kevin Cespedes Arancibia","userId":"15919322234379898396"}},"outputId":"04da384f-19a6-4b2f-dd24-58abe6bf2d58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loss in epoch 1 iteration 0: 1.4010261297225952\n","loss in epoch 1 iteration 1: 1.3450183868408203\n","loss in epoch 1 iteration 2: 1.2846227884292603\n","loss in epoch 1 iteration 3: 1.2048124074935913\n","loss in epoch 2 iteration 0: 1.1600264310836792\n","loss in epoch 2 iteration 1: 1.1409796476364136\n","loss in epoch 2 iteration 2: 1.0514711141586304\n","loss in epoch 2 iteration 3: 1.0122687816619873\n","loss in epoch 3 iteration 0: 0.9672465324401855\n","loss in epoch 3 iteration 1: 0.9296584129333496\n","loss in epoch 3 iteration 2: 0.884010910987854\n","loss in epoch 3 iteration 3: 0.850741982460022\n","loss in epoch 4 iteration 0: 0.7496381998062134\n","loss in epoch 4 iteration 1: 0.7228531241416931\n","loss in epoch 4 iteration 2: 0.6824131011962891\n","loss in epoch 4 iteration 3: 0.6983879208564758\n","loss in epoch 5 iteration 0: 0.6494124531745911\n","loss in epoch 5 iteration 1: 0.6382715702056885\n","loss in epoch 5 iteration 2: 0.6181628704071045\n","loss in epoch 5 iteration 3: 0.610024631023407\n","loss in epoch 6 iteration 0: 0.5867903828620911\n","loss in epoch 6 iteration 1: 0.5722217559814453\n","loss in epoch 6 iteration 2: 0.5489782691001892\n","loss in epoch 6 iteration 3: 0.5281111001968384\n","loss in epoch 7 iteration 0: 0.5087785124778748\n","loss in epoch 7 iteration 1: 0.4928460419178009\n","loss in epoch 7 iteration 2: 0.46779441833496094\n","loss in epoch 7 iteration 3: 0.4565632939338684\n","loss in epoch 8 iteration 0: 0.4395744204521179\n","loss in epoch 8 iteration 1: 0.425190806388855\n","loss in epoch 8 iteration 2: 0.42020684480667114\n","loss in epoch 8 iteration 3: 0.4023127555847168\n","loss in epoch 9 iteration 0: 0.38406360149383545\n","loss in epoch 9 iteration 1: 0.38333481550216675\n","loss in epoch 9 iteration 2: 0.36086320877075195\n","loss in epoch 9 iteration 3: 0.36057186126708984\n","loss in epoch 10 iteration 0: 0.3366641104221344\n","loss in epoch 10 iteration 1: 0.32644376158714294\n","loss in epoch 10 iteration 2: 0.3278401494026184\n","loss in epoch 10 iteration 3: 0.3114505112171173\n","loss in epoch 11 iteration 0: 0.30081337690353394\n","loss in epoch 11 iteration 1: 0.29026854038238525\n","loss in epoch 11 iteration 2: 0.2879033386707306\n","loss in epoch 11 iteration 3: 0.2793648838996887\n","loss in epoch 12 iteration 0: 0.269849956035614\n","loss in epoch 12 iteration 1: 0.2638280391693115\n","loss in epoch 12 iteration 2: 0.25570520758628845\n","loss in epoch 12 iteration 3: 0.2461770474910736\n","loss in epoch 13 iteration 0: 0.23651191592216492\n","loss in epoch 13 iteration 1: 0.23622862994670868\n","loss in epoch 13 iteration 2: 0.2351192831993103\n","loss in epoch 13 iteration 3: 0.21896612644195557\n","loss in epoch 14 iteration 0: 0.2189309298992157\n","loss in epoch 14 iteration 1: 0.21102993190288544\n","loss in epoch 14 iteration 2: 0.20418186485767365\n","loss in epoch 14 iteration 3: 0.197018563747406\n","loss in epoch 15 iteration 0: 0.1958497166633606\n","loss in epoch 15 iteration 1: 0.18945282697677612\n","loss in epoch 15 iteration 2: 0.18708950281143188\n","loss in epoch 15 iteration 3: 0.1792292594909668\n","loss in epoch 16 iteration 0: 0.17448073625564575\n","loss in epoch 16 iteration 1: 0.1708827167749405\n","loss in epoch 16 iteration 2: 0.16932934522628784\n","loss in epoch 16 iteration 3: 0.1671489030122757\n","loss in epoch 17 iteration 0: 0.16133016347885132\n","loss in epoch 17 iteration 1: 0.1549711525440216\n","loss in epoch 17 iteration 2: 0.1512291133403778\n","loss in epoch 17 iteration 3: 0.1490122377872467\n","loss in epoch 18 iteration 0: 0.14274351298809052\n","loss in epoch 18 iteration 1: 0.1418030560016632\n","loss in epoch 18 iteration 2: 0.13644520938396454\n","loss in epoch 18 iteration 3: 0.1349426805973053\n","loss in epoch 19 iteration 0: 0.1319403201341629\n","loss in epoch 19 iteration 1: 0.1293807029724121\n","loss in epoch 19 iteration 2: 0.12674328684806824\n","loss in epoch 19 iteration 3: 0.1230720728635788\n","loss in epoch 20 iteration 0: 0.12090283632278442\n","loss in epoch 20 iteration 1: 0.1166655644774437\n","loss in epoch 20 iteration 2: 0.11914817988872528\n","loss in epoch 20 iteration 3: 0.11036200821399689\n","........epoch:20, time: 111.731719(s), valid (NDCG@10: 0.2366, HR@10: 0.3625)\n","loss in epoch 21 iteration 0: 0.11249677836894989\n","loss in epoch 21 iteration 1: 0.10500295460224152\n","loss in epoch 21 iteration 2: 0.1065930426120758\n","loss in epoch 21 iteration 3: 0.10372698307037354\n","loss in epoch 22 iteration 0: 0.10364820063114166\n","loss in epoch 22 iteration 1: 0.09764456748962402\n","loss in epoch 22 iteration 2: 0.09644784033298492\n","loss in epoch 22 iteration 3: 0.09538915008306503\n","loss in epoch 23 iteration 0: 0.09335695952177048\n","loss in epoch 23 iteration 1: 0.09144905209541321\n","loss in epoch 23 iteration 2: 0.09184056520462036\n","loss in epoch 23 iteration 3: 0.08670490235090256\n","loss in epoch 24 iteration 0: 0.08943510055541992\n","loss in epoch 24 iteration 1: 0.08144954591989517\n","loss in epoch 24 iteration 2: 0.08581852167844772\n","loss in epoch 24 iteration 3: 0.08220578730106354\n","loss in epoch 25 iteration 0: 0.08030636608600616\n","loss in epoch 25 iteration 1: 0.07879605889320374\n","loss in epoch 25 iteration 2: 0.07600020617246628\n","loss in epoch 25 iteration 3: 0.07539696991443634\n","loss in epoch 26 iteration 0: 0.07473467290401459\n","loss in epoch 26 iteration 1: 0.0717625766992569\n","loss in epoch 26 iteration 2: 0.07322855293750763\n","loss in epoch 26 iteration 3: 0.0704115480184555\n","loss in epoch 27 iteration 0: 0.0702674612402916\n","loss in epoch 27 iteration 1: 0.06713160872459412\n","loss in epoch 27 iteration 2: 0.06545250862836838\n","loss in epoch 27 iteration 3: 0.06562354415655136\n","loss in epoch 28 iteration 0: 0.06273352354764938\n","loss in epoch 28 iteration 1: 0.06316724419593811\n","loss in epoch 28 iteration 2: 0.0643843561410904\n","loss in epoch 28 iteration 3: 0.0631607249379158\n","loss in epoch 29 iteration 0: 0.05939421057701111\n","loss in epoch 29 iteration 1: 0.05980493873357773\n","loss in epoch 29 iteration 2: 0.05897781252861023\n","loss in epoch 29 iteration 3: 0.0584152415394783\n","loss in epoch 30 iteration 0: 0.05784941464662552\n","loss in epoch 30 iteration 1: 0.0538526326417923\n","loss in epoch 30 iteration 2: 0.055382899940013885\n","loss in epoch 30 iteration 3: 0.05338588356971741\n","loss in epoch 31 iteration 0: 0.052776891738176346\n","loss in epoch 31 iteration 1: 0.053048182278871536\n","loss in epoch 31 iteration 2: 0.05260501801967621\n","loss in epoch 31 iteration 3: 0.052248530089855194\n","loss in epoch 32 iteration 0: 0.04939630255103111\n","loss in epoch 32 iteration 1: 0.04808393120765686\n","loss in epoch 32 iteration 2: 0.04910186305642128\n","loss in epoch 32 iteration 3: 0.049041032791137695\n","loss in epoch 33 iteration 0: 0.04827883839607239\n","loss in epoch 33 iteration 1: 0.04669783636927605\n","loss in epoch 33 iteration 2: 0.044710658490657806\n","loss in epoch 33 iteration 3: 0.04342414438724518\n","loss in epoch 34 iteration 0: 0.04351767152547836\n","loss in epoch 34 iteration 1: 0.0423378124833107\n","loss in epoch 34 iteration 2: 0.04254821315407753\n","loss in epoch 34 iteration 3: 0.04245270788669586\n","loss in epoch 35 iteration 0: 0.040668897330760956\n","loss in epoch 35 iteration 1: 0.04205486178398132\n","loss in epoch 35 iteration 2: 0.041765596717596054\n","loss in epoch 35 iteration 3: 0.039961788803339005\n","loss in epoch 36 iteration 0: 0.04029320180416107\n","loss in epoch 36 iteration 1: 0.037734255194664\n","loss in epoch 36 iteration 2: 0.03673945367336273\n","loss in epoch 36 iteration 3: 0.036228861659765244\n","loss in epoch 37 iteration 0: 0.03577503561973572\n","loss in epoch 37 iteration 1: 0.03666680306196213\n","loss in epoch 37 iteration 2: 0.036405861377716064\n","loss in epoch 37 iteration 3: 0.03649476543068886\n","loss in epoch 38 iteration 0: 0.03647330030798912\n","loss in epoch 38 iteration 1: 0.03505535423755646\n","loss in epoch 38 iteration 2: 0.034637853503227234\n","loss in epoch 38 iteration 3: 0.033061109483242035\n","loss in epoch 39 iteration 0: 0.03266562148928642\n","loss in epoch 39 iteration 1: 0.03214162588119507\n","loss in epoch 39 iteration 2: 0.03188103064894676\n","loss in epoch 39 iteration 3: 0.0313495472073555\n","loss in epoch 40 iteration 0: 0.03166088089346886\n","loss in epoch 40 iteration 1: 0.031013306230306625\n","loss in epoch 40 iteration 2: 0.030597016215324402\n","loss in epoch 40 iteration 3: 0.03185703977942467\n","........epoch:40, time: 224.717036(s), valid (NDCG@10: 0.2638, HR@10: 0.3862)\n","loss in epoch 41 iteration 0: 0.028675071895122528\n","loss in epoch 41 iteration 1: 0.030859045684337616\n","loss in epoch 41 iteration 2: 0.0288369320333004\n","loss in epoch 41 iteration 3: 0.029727283865213394\n","loss in epoch 42 iteration 0: 0.029331982135772705\n","loss in epoch 42 iteration 1: 0.02848133072257042\n","loss in epoch 42 iteration 2: 0.028122175484895706\n","loss in epoch 42 iteration 3: 0.026549186557531357\n","loss in epoch 43 iteration 0: 0.02771761082112789\n","loss in epoch 43 iteration 1: 0.0273028202354908\n","loss in epoch 43 iteration 2: 0.02637447416782379\n","loss in epoch 43 iteration 3: 0.02719688042998314\n","loss in epoch 44 iteration 0: 0.026961572468280792\n","loss in epoch 44 iteration 1: 0.02571890503168106\n","loss in epoch 44 iteration 2: 0.025957364588975906\n","loss in epoch 44 iteration 3: 0.025877855718135834\n","loss in epoch 45 iteration 0: 0.024002622812986374\n","loss in epoch 45 iteration 1: 0.02309834212064743\n","loss in epoch 45 iteration 2: 0.023791035637259483\n","loss in epoch 45 iteration 3: 0.022950593382120132\n","loss in epoch 46 iteration 0: 0.02409977838397026\n","loss in epoch 46 iteration 1: 0.0236862413585186\n","loss in epoch 46 iteration 2: 0.022188451141119003\n","loss in epoch 46 iteration 3: 0.023319464176893234\n","loss in epoch 47 iteration 0: 0.02260507270693779\n","loss in epoch 47 iteration 1: 0.02316294051706791\n","loss in epoch 47 iteration 2: 0.022119231522083282\n","loss in epoch 47 iteration 3: 0.02160012163221836\n","loss in epoch 48 iteration 0: 0.021844685077667236\n","loss in epoch 48 iteration 1: 0.01992315985262394\n","loss in epoch 48 iteration 2: 0.0204684566706419\n","loss in epoch 48 iteration 3: 0.020966138690710068\n","loss in epoch 49 iteration 0: 0.021194055676460266\n","loss in epoch 49 iteration 1: 0.02050209976732731\n","loss in epoch 49 iteration 2: 0.020791219547390938\n","loss in epoch 49 iteration 3: 0.021436424925923347\n","loss in epoch 50 iteration 0: 0.020064694806933403\n","loss in epoch 50 iteration 1: 0.020021116361021996\n","loss in epoch 50 iteration 2: 0.01873539760708809\n","loss in epoch 50 iteration 3: 0.018538400530815125\n","loss in epoch 51 iteration 0: 0.01934007741510868\n","loss in epoch 51 iteration 1: 0.01766766980290413\n","loss in epoch 51 iteration 2: 0.018587639555335045\n","loss in epoch 51 iteration 3: 0.017603769898414612\n","loss in epoch 52 iteration 0: 0.018244029954075813\n","loss in epoch 52 iteration 1: 0.01767396740615368\n","loss in epoch 52 iteration 2: 0.01860188879072666\n","loss in epoch 52 iteration 3: 0.01798328384757042\n","loss in epoch 53 iteration 0: 0.01756761223077774\n","loss in epoch 53 iteration 1: 0.018035605549812317\n","loss in epoch 53 iteration 2: 0.015862829983234406\n","loss in epoch 53 iteration 3: 0.016522038727998734\n","loss in epoch 54 iteration 0: 0.017390204593539238\n","loss in epoch 54 iteration 1: 0.01716787740588188\n","loss in epoch 54 iteration 2: 0.015495488420128822\n","loss in epoch 54 iteration 3: 0.015666089951992035\n","loss in epoch 55 iteration 0: 0.015315006487071514\n","loss in epoch 55 iteration 1: 0.016017749905586243\n","loss in epoch 55 iteration 2: 0.015371181070804596\n","loss in epoch 55 iteration 3: 0.01527570653706789\n","loss in epoch 56 iteration 0: 0.015511726960539818\n","loss in epoch 56 iteration 1: 0.015248635783791542\n","loss in epoch 56 iteration 2: 0.014914106577634811\n","loss in epoch 56 iteration 3: 0.015529295429587364\n","loss in epoch 57 iteration 0: 0.01517101563513279\n","loss in epoch 57 iteration 1: 0.014278617687523365\n","loss in epoch 57 iteration 2: 0.013894110918045044\n","loss in epoch 57 iteration 3: 0.013928063213825226\n","loss in epoch 58 iteration 0: 0.013620550744235516\n","loss in epoch 58 iteration 1: 0.014903441071510315\n","loss in epoch 58 iteration 2: 0.013738611713051796\n","loss in epoch 58 iteration 3: 0.01490122638642788\n","loss in epoch 59 iteration 0: 0.013202253729104996\n","loss in epoch 59 iteration 1: 0.013944528996944427\n","loss in epoch 59 iteration 2: 0.013666927814483643\n","loss in epoch 59 iteration 3: 0.013197206892073154\n","loss in epoch 60 iteration 0: 0.012529009953141212\n","loss in epoch 60 iteration 1: 0.013354325667023659\n","loss in epoch 60 iteration 2: 0.013293186202645302\n","loss in epoch 60 iteration 3: 0.013053633272647858\n","........epoch:60, time: 337.724252(s), valid (NDCG@10: 0.2618, HR@10: 0.3650)\n","loss in epoch 61 iteration 0: 0.011848005466163158\n","loss in epoch 61 iteration 1: 0.012709815055131912\n","loss in epoch 61 iteration 2: 0.013155660592019558\n","loss in epoch 61 iteration 3: 0.013396553695201874\n","loss in epoch 62 iteration 0: 0.01296783797442913\n","loss in epoch 62 iteration 1: 0.01196707971394062\n","loss in epoch 62 iteration 2: 0.012117179110646248\n","loss in epoch 62 iteration 3: 0.014009545557200909\n","loss in epoch 63 iteration 0: 0.010942080989480019\n","loss in epoch 63 iteration 1: 0.012999111786484718\n","loss in epoch 63 iteration 2: 0.011143054813146591\n","loss in epoch 63 iteration 3: 0.012314371764659882\n","loss in epoch 64 iteration 0: 0.011109012179076672\n","loss in epoch 64 iteration 1: 0.011542189866304398\n","loss in epoch 64 iteration 2: 0.01172346156090498\n","loss in epoch 64 iteration 3: 0.012491760775446892\n","loss in epoch 65 iteration 0: 0.011737681925296783\n","loss in epoch 65 iteration 1: 0.011035876348614693\n","loss in epoch 65 iteration 2: 0.010548661462962627\n","loss in epoch 65 iteration 3: 0.010622000321745872\n","loss in epoch 66 iteration 0: 0.010611634701490402\n","loss in epoch 66 iteration 1: 0.010018191300332546\n","loss in epoch 66 iteration 2: 0.009903493337333202\n","loss in epoch 66 iteration 3: 0.010805022902786732\n","loss in epoch 67 iteration 0: 0.010948226787149906\n","loss in epoch 67 iteration 1: 0.010234124958515167\n","loss in epoch 67 iteration 2: 0.010395471937954426\n","loss in epoch 67 iteration 3: 0.010738199576735497\n","loss in epoch 68 iteration 0: 0.01037319004535675\n","loss in epoch 68 iteration 1: 0.00946173258125782\n","loss in epoch 68 iteration 2: 0.009841009974479675\n","loss in epoch 68 iteration 3: 0.0100778853520751\n","loss in epoch 69 iteration 0: 0.009881076402962208\n","loss in epoch 69 iteration 1: 0.0101784598082304\n","loss in epoch 69 iteration 2: 0.009057383053004742\n","loss in epoch 69 iteration 3: 0.009191913530230522\n","loss in epoch 70 iteration 0: 0.01002425141632557\n","loss in epoch 70 iteration 1: 0.009549509733915329\n","loss in epoch 70 iteration 2: 0.009976465255022049\n","loss in epoch 70 iteration 3: 0.009737555868923664\n","loss in epoch 71 iteration 0: 0.0098918741568923\n","loss in epoch 71 iteration 1: 0.009658267721533775\n","loss in epoch 71 iteration 2: 0.008790341205894947\n","loss in epoch 71 iteration 3: 0.009345405735075474\n","loss in epoch 72 iteration 0: 0.008882268331944942\n","loss in epoch 72 iteration 1: 0.009348850697278976\n","loss in epoch 72 iteration 2: 0.008442236110568047\n","loss in epoch 72 iteration 3: 0.008979001082479954\n","loss in epoch 73 iteration 0: 0.00915793888270855\n","loss in epoch 73 iteration 1: 0.008134633302688599\n","loss in epoch 73 iteration 2: 0.008518865332007408\n","loss in epoch 73 iteration 3: 0.008325060829520226\n","loss in epoch 74 iteration 0: 0.009120907634496689\n","loss in epoch 74 iteration 1: 0.008146623149514198\n","loss in epoch 74 iteration 2: 0.008358395658433437\n","loss in epoch 74 iteration 3: 0.007657540030777454\n","loss in epoch 75 iteration 0: 0.008858984336256981\n","loss in epoch 75 iteration 1: 0.008105779066681862\n","loss in epoch 75 iteration 2: 0.00836188904941082\n","loss in epoch 75 iteration 3: 0.007692441344261169\n","loss in epoch 76 iteration 0: 0.008446171879768372\n","loss in epoch 76 iteration 1: 0.008405939675867558\n","loss in epoch 76 iteration 2: 0.007294595241546631\n","loss in epoch 76 iteration 3: 0.009126260876655579\n","loss in epoch 77 iteration 0: 0.008625288493931293\n","loss in epoch 77 iteration 1: 0.007810227572917938\n","loss in epoch 77 iteration 2: 0.008392808958888054\n","loss in epoch 77 iteration 3: 0.00782355573028326\n","loss in epoch 78 iteration 0: 0.007946721278131008\n","loss in epoch 78 iteration 1: 0.00746015552431345\n","loss in epoch 78 iteration 2: 0.007793356664478779\n","loss in epoch 78 iteration 3: 0.007500833831727505\n","loss in epoch 79 iteration 0: 0.007067224942147732\n","loss in epoch 79 iteration 1: 0.007569383829832077\n","loss in epoch 79 iteration 2: 0.007555229589343071\n","loss in epoch 79 iteration 3: 0.007419101893901825\n","loss in epoch 80 iteration 0: 0.007831068709492683\n","loss in epoch 80 iteration 1: 0.0066687543876469135\n","loss in epoch 80 iteration 2: 0.006862425245344639\n","loss in epoch 80 iteration 3: 0.0076207653619349\n","........epoch:80, time: 450.674819(s), valid (NDCG@10: 0.2613, HR@10: 0.3750)\n","loss in epoch 81 iteration 0: 0.007101140916347504\n","loss in epoch 81 iteration 1: 0.0070757512003183365\n","loss in epoch 81 iteration 2: 0.007745685055851936\n","loss in epoch 81 iteration 3: 0.006678278557956219\n","loss in epoch 82 iteration 0: 0.008250949904322624\n","loss in epoch 82 iteration 1: 0.006182914599776268\n","loss in epoch 82 iteration 2: 0.008394788950681686\n","loss in epoch 82 iteration 3: 0.007633451838046312\n","loss in epoch 83 iteration 0: 0.007238748483359814\n","loss in epoch 83 iteration 1: 0.005619878880679607\n","loss in epoch 83 iteration 2: 0.006427496671676636\n","loss in epoch 83 iteration 3: 0.008468404412269592\n","loss in epoch 84 iteration 0: 0.007163867354393005\n","loss in epoch 84 iteration 1: 0.0068383971229195595\n","loss in epoch 84 iteration 2: 0.006938498467206955\n","loss in epoch 84 iteration 3: 0.006842507049441338\n","loss in epoch 85 iteration 0: 0.006901906803250313\n","loss in epoch 85 iteration 1: 0.007057861890643835\n","loss in epoch 85 iteration 2: 0.006740914657711983\n","loss in epoch 85 iteration 3: 0.00632270285859704\n","loss in epoch 86 iteration 0: 0.005509055685251951\n","loss in epoch 86 iteration 1: 0.006209462881088257\n","loss in epoch 86 iteration 2: 0.006143118254840374\n","loss in epoch 86 iteration 3: 0.005888974294066429\n","loss in epoch 87 iteration 0: 0.007262370549142361\n","loss in epoch 87 iteration 1: 0.006622421555221081\n","loss in epoch 87 iteration 2: 0.006168471183627844\n","loss in epoch 87 iteration 3: 0.005516849458217621\n","loss in epoch 88 iteration 0: 0.006647111847996712\n","loss in epoch 88 iteration 1: 0.0065157124772667885\n","loss in epoch 88 iteration 2: 0.007051452063024044\n","loss in epoch 88 iteration 3: 0.005799632519483566\n","loss in epoch 89 iteration 0: 0.007017068564891815\n","loss in epoch 89 iteration 1: 0.005473822820931673\n","loss in epoch 89 iteration 2: 0.005955778993666172\n","loss in epoch 89 iteration 3: 0.005870919208973646\n","loss in epoch 90 iteration 0: 0.00563464593142271\n","loss in epoch 90 iteration 1: 0.006146006286144257\n","loss in epoch 90 iteration 2: 0.00609344569966197\n","loss in epoch 90 iteration 3: 0.006307574920356274\n","loss in epoch 91 iteration 0: 0.005303344689309597\n","loss in epoch 91 iteration 1: 0.006837209686636925\n","loss in epoch 91 iteration 2: 0.004791078623384237\n","loss in epoch 91 iteration 3: 0.005931379273533821\n","loss in epoch 92 iteration 0: 0.006171083077788353\n","loss in epoch 92 iteration 1: 0.005693652667105198\n","loss in epoch 92 iteration 2: 0.005631040316075087\n","loss in epoch 92 iteration 3: 0.005353186745196581\n","loss in epoch 93 iteration 0: 0.004977420903742313\n","loss in epoch 93 iteration 1: 0.006062452681362629\n","loss in epoch 93 iteration 2: 0.005530091002583504\n","loss in epoch 93 iteration 3: 0.00536936242133379\n","loss in epoch 94 iteration 0: 0.005461274646222591\n","loss in epoch 94 iteration 1: 0.005254734307527542\n","loss in epoch 94 iteration 2: 0.004888002295047045\n","loss in epoch 94 iteration 3: 0.005359112285077572\n","loss in epoch 95 iteration 0: 0.005056306254118681\n","loss in epoch 95 iteration 1: 0.0061271898448467255\n","loss in epoch 95 iteration 2: 0.005152242258191109\n","loss in epoch 95 iteration 3: 0.005735446698963642\n","loss in epoch 96 iteration 0: 0.006929504685103893\n","loss in epoch 96 iteration 1: 0.005726490169763565\n","loss in epoch 96 iteration 2: 0.005092431325465441\n","loss in epoch 96 iteration 3: 0.008692525327205658\n","loss in epoch 97 iteration 0: 0.004941561724990606\n","loss in epoch 97 iteration 1: 0.0059213219210505486\n","loss in epoch 97 iteration 2: 0.006129775661975145\n","loss in epoch 97 iteration 3: 0.00901239924132824\n","loss in epoch 98 iteration 0: 0.019211063161492348\n","loss in epoch 98 iteration 1: 0.009222794324159622\n","loss in epoch 98 iteration 2: 0.007743658497929573\n","loss in epoch 98 iteration 3: 0.014071707613766193\n","loss in epoch 99 iteration 0: 0.010677477344870567\n","loss in epoch 99 iteration 1: 0.010464022867381573\n","loss in epoch 99 iteration 2: 0.011621357873082161\n","loss in epoch 99 iteration 3: 0.011043252423405647\n","loss in epoch 100 iteration 0: 0.009323786944150925\n","loss in epoch 100 iteration 1: 0.013315455988049507\n","loss in epoch 100 iteration 2: 0.011236153542995453\n","loss in epoch 100 iteration 3: 0.013209030032157898\n","........epoch:100, time: 563.625653(s), valid (NDCG@10: 0.2397, HR@10: 0.3187)\n","Done\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt"],"metadata":{"id":"ATJ7WT56bdRQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(train_losses)\n","plt.title('Loss (SASRec)')\n","plt.ylabel('Loss')\n","plt.xlabel('Iteration')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"GenoxkrubZ-J","executionInfo":{"status":"ok","timestamp":1733336982082,"user_tz":180,"elapsed":521,"user":{"displayName":"Kevin Cespedes Arancibia","userId":"15919322234379898396"}},"outputId":"de201fca-1fe0-4bf6-ccd6-c97998397549"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["def read_interactions(file):\n","  ui_mat = np.loadtxt(f'{file}', dtype=np.int32)\n","  return ui_mat"],"metadata":{"id":"8cbWy_1ZLmBT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_challenge_file_path = '/content/drive/My Drive/puc/rec/project/data/test_challenge_200p.txt'\n","test_challenge_dataset = read_interactions(test_challenge_file_path)"],"metadata":{"id":"BZPhNWw7Lnl9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math"],"metadata":{"id":"uWmSwmkVLznO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dcg(recommended_items, rel_items_labels):\n","  dcg_value = 0\n","  for idx, rel in enumerate(rel_items_labels):\n","    i = idx + 1\n","    dcg_value += ((2**rel-1)/math.log2(i + 1))\n","  return dcg_value\n","\n","def ndcg(recommended_items, relevant_items):\n","  rel_items_labels = np.isin(recommended_items, relevant_items)\n","  count_rel_items = np.sum(rel_items_labels)\n","  ideal_rel_items_labels = np.concatenate([np.ones(count_rel_items, dtype=int), np.zeros(len(rel_items_labels) - count_rel_items, dtype=int)])\n","  dcg_value = dcg(recommended_items, rel_items_labels)\n","  ideal_dcg_value = dcg(recommended_items, ideal_rel_items_labels)\n","  ndcg_value = 0\n","  if dcg_value != 0:\n","    ndcg_value = dcg_value / ideal_dcg_value\n","  return ndcg_value"],"metadata":{"id":"Sv0Sxdh8LxiS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from itertools import combinations"],"metadata":{"id":"T1TyuJOLx-cV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idx2uri = read_json_file(f'{data_dir}/idx2uri.json')\n","genres = read_json_file(f'{data_dir}/uri2genres.json')"],"metadata":{"id":"MkQpkAdJ8D3W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def id2genre(idx):\n","  uri = idx2uri[str(idx)]\n","  if uri in genres:\n","    return genres[uri]\n","  else:\n","    return 'None'"],"metadata":{"id":"ahzPPVFNAb8F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def recall_at_k(relevant_items, recommended_items, k):\n","    relevant_items = set(relevant_items)\n","    recommended_items = set(recommended_items[:k])\n","    intersection = relevant_items.intersection(recommended_items)\n","    recall = len(intersection) / len(relevant_items)\n","    return recall\n","\n","def precision_at_k(relevant_items, recommended_items, k):\n","    \"\"\"\n","    Calcula la precisin en los primeros k elementos recomendados.\n","\n","    Parameters:\n","        relevant_items (list): Lista de elementos relevantes.\n","        recommended_items (list): Lista ordenada de elementos recomendados.\n","        k (int): Nmero de elementos recomendados a considerar.\n","\n","    Returns:\n","        float: Precision@k.\n","    \"\"\"\n","    relevant_items = set(relevant_items)\n","    recommended_items = recommended_items[:k]\n","    relevant_recommended = [item for item in recommended_items if item in relevant_items]\n","    precision = len(relevant_recommended) / k\n","    return precision"],"metadata":{"id":"BwYEBkN9ATW5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dcg(recommended_items, rel_items_labels):\n","  dcg_value = 0\n","  for idx, rel in enumerate(rel_items_labels):\n","    i = idx + 1\n","    dcg_value += ((2**rel-1)/math.log2(i + 1))\n","  return dcg_value\n","\n","def ndcg_eq(recommended_items, relevant_items, k=10):\n","  recommended_items = recommended_items[:k]\n","  rel_items_labels = np.isin(recommended_items, relevant_items)\n","  count_rel_items = np.sum(rel_items_labels)\n","  ideal_rel_items_labels = np.concatenate([np.ones(count_rel_items, dtype=int), np.zeros(len(rel_items_labels) - count_rel_items, dtype=int)])\n","  dcg_value = dcg(recommended_items, rel_items_labels)\n","  ideal_dcg_value = dcg(recommended_items, ideal_rel_items_labels)\n","  ndcg_value = 0\n","  if dcg_value != 0:\n","    ndcg_value = dcg_value / ideal_dcg_value\n","  return ndcg_value"],"metadata":{"id":"ZUFTqvteAWSI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from itertools import combinations"],"metadata":{"id":"ic-lObtPo8Xh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def diversity_at_n(recommendations, n):\n","    genres = [id2genre(id) for id in recommendations]\n","    genres = genres[:n]\n","    num_elements = len(genres)\n","\n","    if num_elements <= 1:\n","        return 0\n","\n","    def distance(genre1, genre2):\n","        return 1 if genre1 != genre2 else 0\n","\n","    pairwise_distances = [\n","        distance(g1, g2) for g1, g2 in combinations(genres, 2)\n","    ]\n","    return sum(pairwise_distances) / len(pairwise_distances)"],"metadata":{"id":"cRrnTSiUAX4X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_metrics(recommendations, relevant_items, k=10):\n","    #ndcg = calculate_ndcg(recommendations, relevant_items, k)\n","    ndcg = ndcg_eq(recommendations, relevant_items, k)\n","    recall = recall_at_k(relevant_items, recommendations, k)\n","    precision = precision_at_k(relevant_items, recommendations, k)\n","    diversity = diversity_at_n(recommendations, k)\n","    return ndcg, recall, precision, diversity"],"metadata":{"id":"G3NaIFVdAZBu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval(test_interactions_dataset, train, k=25, n_inputs = 5, n_playlists = 200):\n","  ndcgs = []\n","  recalls = []\n","  precisions = []\n","  diversities = []\n","  tracks_per_playlist = int(len(test_interactions_dataset) / n_playlists)\n","  interactions_idx = 0\n","  while interactions_idx < len(test_interactions_dataset):\n","    input_items = []\n","    playlist_id = test_interactions_dataset[interactions_idx][0]\n","    while len(input_items) < n_inputs:\n","      input_items.append(test_interactions_dataset[interactions_idx][1])\n","      interactions_idx += 1\n","    ground_trouth_items = []\n","    while len(ground_trouth_items) < tracks_per_playlist - n_inputs:\n","      ground_trouth_items.append(test_interactions_dataset[interactions_idx][1])\n","      interactions_idx += 1\n","\n","    seq = np.zeros([args.maxlen], dtype=np.int32)\n","    idx = args.maxlen - 1\n","    for i in reversed(input_items):\n","        seq[idx] = i\n","        idx -= 1\n","        if idx == -1: break\n","\n","    input_seq_set = set(input_items)\n","    candidate_items = []\n","    for item in list(range(1,itemnum + 1)):\n","      if item not in input_seq_set:\n","        candidate_items.append(item)\n","\n","    predictions = -model.predict(*[np.array(l) for l in [[playlist_id], [seq], candidate_items]])\n","    predictions = predictions[0]\n","    predicted_tracks = []\n","    for candidate_item_idx in predictions.argsort():\n","      predicted_tracks.append(candidate_items[candidate_item_idx])\n","    ndcg_val, recall_val, precision_val, diversity_val = get_metrics(predicted_tracks, ground_trouth_items, k=k)\n","    ndcgs.append(ndcg_val)\n","    recalls.append(recall_val)\n","    precisions.append(precision_val)\n","    diversities.append(diversity_val)\n","  return np.mean(ndcgs), np.mean(recalls), np.mean(precisions), np.mean(diversities)"],"metadata":{"id":"nU1dw4zCK8fp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ndcg_10_1, recall_10_1, precision_10_1, diversity_10_1 = eval(test_challenge_dataset, user_train, k = 10, n_inputs = 1)\n","ndcg_20_1, recall_20_1, precision_20_1, diversity_20_1 = eval(test_challenge_dataset, user_train, k = 20, n_inputs = 1)\n","ndcg_25_1, recall_25_1, precision_25_1, diversity_25_1 = eval(test_challenge_dataset, user_train, k = 25, n_inputs = 1)\n","\n","ndcg_10_5, recall_10_5, precision_10_5, diversity_10_5 = eval(test_challenge_dataset, user_train, k = 10, n_inputs = 5)\n","ndcg_20_5, recall_20_5, precision_20_5, diversity_20_5 = eval(test_challenge_dataset, user_train, k = 20, n_inputs = 5)\n","ndcg_25_5, recall_25_5, precision_25_5, diversity_25_5 = eval(test_challenge_dataset, user_train, k = 25, n_inputs = 5)\n","\n","print('Input: 1 track')\n","print('@10 NDCG {} Reccall {} Precision {} Diversity {}'.format(ndcg_10_1, recall_10_1, precision_10_1, diversity_10_1))\n","print('@20 NDCG {} Reccall {} Precision {} Diversity {}'.format(ndcg_20_1, recall_20_1, precision_20_1, diversity_20_1))\n","print('@25 NDCG {} Reccall {} Precision {} Diversity {}'.format(ndcg_25_1, recall_25_1, precision_25_1, diversity_25_1))\n","\n","print('Input: 5 tracks')\n","print('@10 NDCG {} Reccall {} Precision {} Diversity {}'.format(ndcg_10_5, recall_10_5, precision_10_5, diversity_10_5))\n","print('@20 NDCG {} Reccall {} Precision {} Diversity {}'.format(ndcg_20_5, recall_20_5, precision_20_5, diversity_20_5))\n","print('@20 NDCG {} Reccall {} Precision {} Diversity {}'.format(ndcg_25_5, recall_25_5, precision_25_5, diversity_25_5))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"toOhLUEtx-U-","executionInfo":{"status":"ok","timestamp":1733337900586,"user_tz":180,"elapsed":831023,"user":{"displayName":"Kevin Cespedes Arancibia","userId":"15919322234379898396"}},"outputId":"ae27f0a6-7e04-40d3-e8af-1f78a9a725d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 1 track\n","@10 NDCG 0.1501594374073178 Reccall 0.014193349753694582 Precision 0.040999999999999995 Diversity 0.8388888888888889\n","@20 NDCG 0.16440004375965472 Reccall 0.023541096515234443 Precision 0.034 Diversity 0.8643947368421052\n","@25 NDCG 0.16789114720376305 Reccall 0.02734035759897829 Precision 0.0316 Diversity 0.8700666666666667\n","Input: 5 tracks\n","@10 NDCG 0.09306811895293275 Reccall 0.011408333333333333 Precision 0.0285 Diversity 0.8515555555555556\n","@20 NDCG 0.11110917393400875 Reccall 0.02001666666666667 Precision 0.025 Diversity 0.8709736842105263\n","@20 NDCG 0.11896947989174801 Reccall 0.022616666666666667 Precision 0.022600000000000002 Diversity 0.8742833333333333\n"]}]}]}